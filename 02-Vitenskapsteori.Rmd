# Vitenskapsteori

## 1. Falsifikasjonisme

Når man skal diskutere falsifikasjon, er det flere spørsmål som er aktuelle, hva er vitenskap? er alt som blir publisert vitenskap, og hvor går i så fall skillet mellom vitenskap og «ikke-vitenskap»? Sistnevnte er kjent som demarkasjonsproblemet.

Spørsmålene som jeg stiller over, er spørsmål som har vært diskutert av vitenskapsfilosofer lenge og spesielt de siste hundre årene [@okasha2016] . Karl Raimond Popper har hatt og har stor innflytelse i disse spørsmålene etter at han kom med sin teori om falsifikasjonskriteriet [@okasha2016] . Denne teorien sier at en vitenskapelig teori må kunne være mulig å falsifisere (motbevise) [@popper2002]. Dermed kommer Popper med en løsning på Demarkasjonsproblemet, vitenskap er teorier som teoretisk sett skal være mulig å motbevise [@popper2002]. En teori som ikke kan motbevises er da ikke-vitenskap, eller som Popper ville sagt, pseudovitenskap [@popper2002]. Popper løfter fram Astrologi som et eksempel på pseudovitenskap, da det ikke er mulig å falsifisere [@popper2002]. Astrologer baserer seg på empiriske observasjoner og danner horoskoper med vage teorier sånn at de kan bortforklare et hvert angrep mot læren [@popper2002]. Dette blir på mange måter det motsatte av det Popper ønsker [@popper2002]. En forsker skal heller sette seg teorier for å så ha som mål å falsifisere de, på denne måten vil man sikre god vitenskap [@popper2002]. Når man prøver å falsifisere en teori vil det være gjennom deduksjon, teorien har et premiss som empirisk blir testet og man får svaret sant eller usant. Utfallet blir da enten at teorien blir falsifisert og da lagt fram som motbevist eller at teorien blir stående. Ifølge Popper kan ikke teorier bevises, og da er argumentasjon basert på induksjon heller aldri et alternativ [@okasha2016]. Samtidig mener Popper at teorier som har blitt testet på riktige måter og som ikke har blitt falsifisert, kan bli «corroborated», altså nesten bevist [@popper2002]. Poppers tanker om disse teoriene som flere ganer ikke er blitt falsifisert ligner da veldig på en induktiv bekreftelse av en teori, altså når en teori som mest sannsynlig er sann, men ifølge Popper er det ikke det samme [@okasha2016; @popper2002].

Problemet med Poppers teori om vitenskap kommer tydelig fram når han ikke kan bekrefte vitenskapelige teorier. Samir Okasha får dette fram i sin bok om vitenskapsfilosofi [@okasha2016]. Okasha løfter fram et eksempel om personer med Downs Syndrom: Genforskere har funnet ut at alle som har Down Syndrom har tre kopier av kromosomnummer 21 istedenfor to [@okasha2016, s. 18]. Genforskere har da basert på et stort utvalg med personer som har Down Syndrom gjort en konklusjon som gjelder alle med Down Syndrom [@okasha2016]. Dette er da en induktivt bekreftet teori som er godt dokumentert og som gjør at man kan bygge videre kunnskap basert på teorien. Popper kunne ikke gjort dette da det ikke er mulig å gjøre så sterke påstander [@okasha2016]. På bakgrunn av dette skulle man ikke trenger å svare på demarkasjonsproblemet og heller skille mellom styrket og mindre styrket teorier. Okasha mener at en forskeres rolle ikke bare handler om å finne ut om en teori er usann, men også å finne hvilke teorier som er sanne eller mest sannsynlig sanne, og da trenger man induksjon [@okasha2016, s. 19--20]

## 2. HD-metoden og abduksjon/Bayesisme


I oppgave 1 så jeg på hva en vitenskapelig teori er, nå skal jeg se på hvordan teorier kan testes. Carl Gustav Hempel mente at det ikke fantes noen god metode teorier kunne testes og var uenig med Popper [@hempel1966]. Hempel mente at man trengte induktiv argumentasjon i vitenskapene [@hempel1966]. Derfor løftet Hempel fram en metode kaldt hypotetisk deduktiv metode (HD-metoden), som et bedre alternativ [@hempel1966]. Denne metoden sier ikke noe om hvordan teorier kommer fram, men den har klare retningslinjer på hvordan man skal teste en teori og gi den styrke [@hempel1966].

For å forklare HD-metoden bruker jeg følgende eksempel som teori: Høyintensitets intervalltrening på løp øker det maksimale oksygenopptaket (VO~2maks~). Ifølge HD-metoden skal man etter at en har utarbeidet en teori tenke ut empiriske konsekvenser til teorien [@hempel1966]. I vårt tilfelle er det da å finne hvilke empiriske konsekvenser det er av å få et høyrere VO~2maks~. Man skulle tro at empiriske konsekvenser av høyere VO~2maks~ er et høyere blodvolum og bedre prestasjon på 5min løpstest. Neste steg er å teste om de empiriske konsekvensene er sanne, dette skjer gjennom deduktiv testing [@hempel1966]. Dette betyr at økt blodvolum og bedre prestasjon på 5min løpstest blir satt som premiss for at teorien. Om blodvolumet da har økt og prestasjonen på 5min løpstest har blitt bedre, gir det en styrke til teorien om at høyintensiv intervalltrening gir høyere VO~2maks~. I vanlig deduktiv argumentasjon vil et rett premiss bety at teorien er sann, men i HD-metoden vil teorien bare bli en grad av induktivt bekreftet [@hempel1966]. HD-metoden vil aldri si at en teori er bekreftet, da det ikke er mulig å vite om alle argument som kan forklarer teorien [@hempel1966]. Man kan også tenke seg at det er observasjoner eller resultat som kommer i fremtiden og som motsier det en har trodd før [@hempel1966]. I vårt eksempel kan en se for seg at høyintensitets intervalltrening under noen forhold ikke gir høyere blodvolum eller bedre prestasjon på 5min løpstest. HD-metoden er alltid åpen for at det er andre forklaringer og sier derfor bare noe om en teoris styrke eller svakhet ut fra det man har testet empirisk [@hempel1966].

Problemet med HD-metoden er at den empiriske testingen som er bundet til teorien. Det vil si at man ikke kan endre teorien, selv om resultatet av en test ender opp med å passe bedre til en annen teori. Charles Sanders Peirce sin teori kan være løsningen på dette problemet, ved å innføre abduksjon i tillegg til induksjon og deduksjon [@peirce1992]. Abduksjon handler om at man setter flere teorier, for å deretter forklarer teoriene og teste de deduktivt (som i HD-metoden) [@peirce1992]. Resultatet fra testene vil da fortelle oss hvilken teori som er sann, basert på hvilken teori som kan forklarer svarene på testene best [@peirce1992]. En teori som forklarer mest mulig vil være å foretrekke da man i abduksjon ønsker å ha en teori som er bedre enn andre tilgjengelig teorier [@peirce1992]. Abduksjon blir derav også kaldt «slutning til den beste forklaringen» fordi en teori skal gi den beste mulige forklaringen på et fenomen [@peirce1992].

På mange måter ligner HD-metoden og abduksjon på hverandre og begge vil gå under kvalifisert gjetning [@persson2019] . Det som i hovedsak skiller abduksjon fra HD-metoden er fleksibiliteten og den praktiske tilnærmingen da det er flere teorier å velge mellom [@peirce1992].

## 3. Replikasjonskrisen


De siste 20 årene har det blitt identifisert en replikasjonskrise i vitenskapen [@begley2012; @ioannidis2005; @opensciencecollaboration2015]. Dette handler om at mange studier som blir gjort på nytt ikke klarer å få det samme resultatet som første gangen det ble gjort. Det gir oss et stort problem, for hvordan kan man da stole på vitenskapen? Undersøkelser viser at tillitten til vitenskapen har falt i England og USA [@funk2016]. Dette er også noe flertallet av forskere anerkjenner som en krise basert på en spørreundersøkelse gjort på 1500 forskere [@baker2016]. Alexander Bird mener å ha en forklaring til denne replikasjonskrisen [@bird2020].

Bird mener at feilen ligger i en neglisjering av basefrekvens [@bird2020]. Vitenskapen konkluderer rett og slett alt for fort uten å ta hensyn til basefrekvens [@bird2020]. Sånn som vitenskapen er i dag er det typisk gjort en randomisert kontrollert undersøkelse (RTC) og resultatet er enten signifikant eller usignifikant basert på P-verdien [@bird2020]. Denne signifikantgrensen som ofte blir satt til 0,05 (5%) har da blitt en slags pekepinn på om noe er sant eller usant basert på om resultatet er over eller under grensen [@bird2020]. P-verdien sier noe om sannsynligheten for at resultatet er falskt positivt (type-I-feil) [@bird2020]. Om P-verdien er 0,05 er det en 5% sjanse for at resultatet er falskt positiv [@bird2020]. Problemet med dette er at P-verdien man får etter et forskningsprosjekt bare sier noe om utvalget som er sett på i den gitte situasjonen [@bird2020]. Ved å bruke basefrekvens vil man se på resultatet basert på populasjonen og hvor sannsynlig det egentlig er for at resultatet er sant [@bird2020]. Et eksempel på dette, som @bird2020 tar fram, er sannsynligheten for at en tilfeldig har en sjelden sykdom om vedkommende tester positivt på en test. Sykdommen hadde en forekomst på 1 til 1000 og testen hadde en pålitelighet på 95% [@bird2020]. Det er lett å tenke at samsynligheten er 95%, men i realiteten er den 2% [@bird2020]. Dette kommer av at man må regne inn forekomsten i regnestykke gjennom Bayes teorem [@bird2020]. På samme som at det er lett å trekke konklusjonen om at personen i eksempelet var syk, kan vi dra konklusjoner om at vitenskapelige hypoteser er sanne [@bird2020]. Dette gjør at mange studier faktisk ikke gir et rett svar, og da ikke er repliserbare [@bird2020].

Andre forklaringer som Bird trekker fram er den statistiske styrken, som i mange tilfeller ikke er høy nok [@bird2020]. Styrken blir i stor grad styrt av forskningens størrelse (antall deltagere) og gir en sannsynlighet for å ikke få et falskt negativt resultat (type-II-feil) [@bird2020]. Men Bird mener at dette ikke er en god forklaring fordi en høy statistisk styrke egentlig fortsatt gir relativt høy sannsynlighet for å få en type-II-feil [@bird2020]. Bird viser til en utregning hvor det er høyere statistisk styrke enn i «vanlig» vitenskap, men at det fortsatt er 31% sjanse for å få type-II-feil [@bird2020, s. 12-14]. Det vil være bra for vitenskapen å få opp den statistiske styrken, men kan ikke forklarer krisen som vitenskapen står i [@bird2020].

Juks og dårlig praksis i vitenskapen vil kunne forklare noe av replikasjonskrisen, men det er vanskelig å sette en konklusjon basert på det man har sett av studier så langt [@bird2020]. Det er derfor ikke gode nok holdepunkt til å mene at det er dårlig moral rundt vitenskapen som er hele forklaringen på krisen [@bird2020].

Basert på det @bird2020 skriver, er det tydelig at det er hans egen forklaring som gir mest styrke til teorien om at vitenskapen er i en krise. Det er tydelig at folk som driver vitenskap trenger en større forståelse av statistikk og sannsynlighet [@bird2020]. Gjennom et større hensyn til basefrekvensen vil man utarbeide bedre teorier og være mer forsiktig med å si at noe er gjeldene for en hel populasjon [@bird2020].
